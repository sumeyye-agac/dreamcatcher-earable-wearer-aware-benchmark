{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Story: Baselines, CBAM, KD\n",
    "\n",
    "This notebook provides decision-focused analysis on finished experiment artifacts.\n",
    "\n",
    "**Run order:**\n",
    "1. Ensure completed artifacts exist in `results/`\n",
    "2. Open and run this notebook top-to-bottom\n",
    "\n",
    "**Dependencies:** local CSV/JSON artifacts only (no dataset download, no training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CWD = Path.cwd()\n",
    "if (CWD / 'results').exists():\n",
    "    ROOT = CWD\n",
    "elif (CWD.parent / 'results').exists():\n",
    "    ROOT = CWD.parent\n",
    "else:\n",
    "    raise FileNotFoundError('Could not locate repo root containing results/.')\n",
    "MANIFEST_PATH = ROOT / 'experiments' / 'manifest_repro_v1.json'\n",
    "LEADERBOARD_PATH = ROOT / 'results' / 'leaderboard.csv'\n",
    "RUN_STEPS_PATH = ROOT / 'results' / 'run_steps.csv'\n",
    "STATUS_PATH = ROOT / 'results' / 'orchestration' / 'manifest_status.csv'\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.grid'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Campaign Completeness Audit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = json.loads(MANIFEST_PATH.read_text(encoding='utf-8'))\n",
    "leaderboard = pd.read_csv(LEADERBOARD_PATH)\n",
    "status = pd.read_csv(STATUS_PATH)\n",
    "\n",
    "seed = int(manifest['seed'])\n",
    "\n",
    "phase1_expected = (\n",
    "    len(manifest['baseline']['models'])\n",
    "    + len(manifest['baseline']['cbam_models'])\n",
    "    * len(manifest['baseline']['cbam_reduction_values'])\n",
    "    * len(manifest['baseline']['cbam_sa_kernel_values'])\n",
    ")\n",
    "kd_expected = (\n",
    "    len(manifest['kd']['students'])\n",
    "    * len(manifest['kd']['alphas'])\n",
    "    * len(manifest['kd']['temperatures'])\n",
    ")\n",
    "\n",
    "run_status = status[status['run_name'].str.startswith(('p1_', 'p2_'))].copy()\n",
    "latest_status = run_status.sort_values('ts_utc').drop_duplicates('run_name', keep='last')\n",
    "completed = latest_status[latest_status['status'].isin(['ok', 'skipped_valid'])]\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        {'stage': 'phase1', 'expected': phase1_expected, 'completed': int((completed['run_name'].str.startswith('p1_')).sum())},\n",
    "        {'stage': 'phase2_kd', 'expected': kd_expected, 'completed': int((completed['run_name'].str.startswith('p2_kd_')).sum())},\n",
    "    ]\n",
    ")\n",
    "summary['remaining'] = summary['expected'] - summary['completed']\n",
    "display(summary)\n",
    "\n",
    "assert (summary['remaining'] == 0).all(), 'Campaign is not fully complete.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Phase-1 Snapshot (Teacher + Baselines + Best CBAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1 = leaderboard[leaderboard['run_name'].str.startswith('p1_')].copy()\n",
    "phase1_small = phase1[\n",
    "    [\n",
    "        'run_name', 'model', 'params', 'best_val_f1', 'best_val_acc', 'test_f1', 'test_acc',\n",
    "        'cbam_reduction', 'cbam_sa_kernel'\n",
    "    ]\n",
    "].sort_values('test_f1', ascending=False)\n",
    "display(phase1_small.head(12))\n",
    "\n",
    "best_cbam = phase1[phase1['model'] == 'tinycnn_cbam'].sort_values('test_f1', ascending=False).iloc[0]\n",
    "teacher = phase1[phase1['run_name'] == 'p1_crnn_seed42'].iloc[0]\n",
    "tiny_base = phase1[phase1['run_name'] == 'p1_tinycnn_seed42'].iloc[0]\n",
    "\n",
    "print('teacher:', teacher['run_name'], f\"test_f1={teacher['test_f1']:.4f}\", f\"test_acc={teacher['test_acc']:.4f}\")\n",
    "print('tiny base:', tiny_base['run_name'], f\"test_f1={tiny_base['test_f1']:.4f}\", f\"test_acc={tiny_base['test_acc']:.4f}\")\n",
    "print('best cbam:', best_cbam['run_name'], f\"test_f1={best_cbam['test_f1']:.4f}\", f\"test_acc={best_cbam['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) KD vs Non-KD Comparison Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd = leaderboard[leaderboard['run_name'].str.startswith('p2_kd_')].copy()\n",
    "\n",
    "teacher_f1 = float(teacher['test_f1'])\n",
    "\n",
    "base_rows = {\n",
    "    'tinycnn': phase1[phase1['run_name'] == 'p1_tinycnn_seed42'].iloc[0],\n",
    "    'tinycnn_cbam': phase1[phase1['run_name'] == 'p1_tinycnn_cbam_rr8_sk3_seed42'].iloc[0],\n",
    "}\n",
    "\n",
    "def attach_comparison(df, base_row):\n",
    "    out = df.copy()\n",
    "    base_f1 = float(base_row['test_f1'])\n",
    "    base_acc = float(base_row['test_acc'])\n",
    "    out['delta_vs_baseline'] = out['test_f1'] - base_f1\n",
    "    out['delta_acc'] = out['test_acc'] - base_acc\n",
    "    out['teacher_gap_closed'] = (out['test_f1'] - base_f1) / (teacher_f1 - base_f1)\n",
    "    return out[[\n",
    "        'run_name', 'test_f1', 'delta_vs_baseline', 'test_acc', 'delta_acc', 'teacher_gap_closed', 'alpha', 'tau'\n",
    "    ]].sort_values('test_f1', ascending=False)\n",
    "\n",
    "kd_tiny = kd[kd['run_name'].str.startswith('p2_kd_tinycnn_a')]\n",
    "kd_cbam = kd[kd['run_name'].str.startswith('p2_kd_tinycnn_cbam_')]\n",
    "\n",
    "tiny_table = attach_comparison(kd_tiny, base_rows['tinycnn'])\n",
    "cbam_table = attach_comparison(kd_cbam, base_rows['tinycnn_cbam'])\n",
    "\n",
    "print('KD table: tinycnn')\n",
    "display(tiny_table)\n",
    "print('KD table: tinycnn_cbam')\n",
    "display(cbam_table)\n",
    "\n",
    "assert len(tiny_table) + len(cbam_table) == 18, 'Expected 18 KD runs in total.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Hyperparameter View (`alpha x tau`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(df, title):\n",
    "    pivot = df.pivot_table(index='alpha', columns='tau', values='test_f1', aggfunc='mean')\n",
    "    pivot = pivot.sort_index().sort_index(axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    im = ax.imshow(pivot.values, cmap='YlGnBu', aspect='auto')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('tau')\n",
    "    ax.set_ylabel('alpha')\n",
    "    ax.set_xticks(np.arange(len(pivot.columns)))\n",
    "    ax.set_xticklabels([f'{v:g}' for v in pivot.columns])\n",
    "    ax.set_yticks(np.arange(len(pivot.index)))\n",
    "    ax.set_yticklabels([f'{v:g}' for v in pivot.index])\n",
    "\n",
    "    for i in range(pivot.shape[0]):\n",
    "        for j in range(pivot.shape[1]):\n",
    "            ax.text(j, i, f\"{pivot.values[i, j]:.4f}\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label('test_f1')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    display(pivot)\n",
    "\n",
    "plot_heatmap(kd_tiny, 'KD Hyperparameter Surface (tinycnn)')\n",
    "plot_heatmap(kd_cbam, 'KD Hyperparameter Surface (tinycnn_cbam)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Training Dynamics\n",
    "\n",
    "Compare epoch-level trajectories for representative runs:\n",
    "- TinyCNN baseline vs best TinyCNN KD\n",
    "- TinyCNN_CBAM baseline vs best TinyCNN_CBAM KD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs = {\n",
    "    'tiny_baseline': 'p1_tinycnn_seed42',\n",
    "    'tiny_best_kd': tiny_table.iloc[0]['run_name'],\n",
    "    'cbam_baseline': 'p1_tinycnn_cbam_rr8_sk3_seed42',\n",
    "    'cbam_best_kd': cbam_table.iloc[0]['run_name'],\n",
    "}\n",
    "\n",
    "def load_epoch_metrics(run_name):\n",
    "    row = leaderboard[leaderboard['run_name'] == run_name].iloc[0]\n",
    "    p = ROOT / row['epoch_metrics_csv']\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f'Missing epoch metrics: {p}')\n",
    "    d = pd.read_csv(p)\n",
    "    d['run_name'] = run_name\n",
    "    return d\n",
    "\n",
    "epoch_dfs = [load_epoch_metrics(rn) for rn in selected_runs.values()]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for d in epoch_dfs:\n",
    "    axes[0].plot(d['epoch'], d['val_f1_macro'], label=str(d['run_name'].iloc[0]))\n",
    "    axes[1].plot(d['epoch'], d['val_loss'], label=str(d['run_name'].iloc[0]))\n",
    "\n",
    "axes[0].set_title('Validation F1 by Epoch')\n",
    "axes[0].set_xlabel('epoch')\n",
    "axes[0].set_ylabel('val_f1_macro')\n",
    "axes[1].set_title('Validation Loss by Epoch')\n",
    "axes[1].set_xlabel('epoch')\n",
    "axes[1].set_ylabel('val_loss')\n",
    "axes[0].legend(fontsize=7)\n",
    "axes[1].legend(fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Error Profile (Confusion Matrix): Baseline vs Best-KD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_confusion(run_name):\n",
    "    row = leaderboard[leaderboard['run_name'] == run_name].iloc[0]\n",
    "    p = ROOT / row['test_cm_csv']\n",
    "    cm = pd.read_csv(p, index_col=0)\n",
    "    cm = cm.loc[LABELS, LABELS]\n",
    "    return cm\n",
    "\n",
    "LABELS = ['quiet', 'breathe', 'snore']\n",
    "\n",
    "compare_pairs = [\n",
    "    ('tinycnn', 'p1_tinycnn_seed42', tiny_table.iloc[0]['run_name']),\n",
    "    ('tinycnn_cbam', 'p1_tinycnn_cbam_rr8_sk3_seed42', cbam_table.iloc[0]['run_name']),\n",
    "]\n",
    "\n",
    "for name, base_run, kd_run in compare_pairs:\n",
    "    cm_base = load_confusion(base_run)\n",
    "    cm_kd = load_confusion(kd_run)\n",
    "    diff = cm_kd - cm_base\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 3.5))\n",
    "    for ax, mat, title in [\n",
    "        (axes[0], cm_base, f'{name} baseline'),\n",
    "        (axes[1], cm_kd, f'{name} best KD'),\n",
    "        (axes[2], diff, f'{name} KD - baseline'),\n",
    "    ]:\n",
    "        im = ax.imshow(mat.values, cmap='RdYlGn' if 'KD - baseline' in title else 'Blues')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(np.arange(len(LABELS)))\n",
    "        ax.set_yticks(np.arange(len(LABELS)))\n",
    "        ax.set_xticklabels(LABELS, rotation=30)\n",
    "        ax.set_yticklabels(LABELS)\n",
    "        for i in range(mat.shape[0]):\n",
    "            for j in range(mat.shape[1]):\n",
    "                ax.text(j, i, f\"{int(mat.values[i, j])}\", ha='center', va='center', fontsize=8)\n",
    "        fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G) Final Takeaways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tiny = tiny_table.iloc[0]\n",
    "best_cbam = cbam_table.iloc[0]\n",
    "\n",
    "takeaways = [\n",
    "    f\"Phase-1 and KD campaigns are complete: {phase1_expected}/11 and {kd_expected}/18 expected runs matched.\",\n",
    "    f\"Best TinyCNN KD run: {best_tiny['run_name']} (test_f1={best_tiny['test_f1']:.4f}, delta={best_tiny['delta_vs_baseline']:+.4f}).\",\n",
    "    f\"Best TinyCNN_CBAM KD run: {best_cbam['run_name']} (test_f1={best_cbam['test_f1']:.4f}, delta={best_cbam['delta_vs_baseline']:+.4f}).\",\n",
    "    f\"KD benefit is stronger on CBAM student variants (higher teacher-gap closure in top settings).\",\n",
    "    f\"Not every KD setting helps equally; the alpha/tau surface shows clear sensitivity.\",\n",
    "    f\"Use leaderboard + confusion matrices jointly: global gains can still hide class-specific tradeoffs.\",\n",
    "]\n",
    "\n",
    "for i, line in enumerate(takeaways, 1):\n",
    "    print(f\"{i}. {line}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}