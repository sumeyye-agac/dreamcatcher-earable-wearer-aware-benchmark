{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Story: DreamCatcher Cache + Preprocessing\n",
    "\n",
    "This notebook explains the dataset subset and preprocessing artifacts used by the benchmark.\n",
    "\n",
    "**Run order:**\n",
    "1. `python3 scripts/preprocess.py`\n",
    "2. Open and run this notebook\n",
    "\n",
    "**Dependencies:** only local cache artifacts under `results/cache/spectrograms/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "CWD = Path.cwd()\n",
    "if (CWD / 'results').exists():\n",
    "    ROOT = CWD\n",
    "elif (CWD.parent / 'results').exists():\n",
    "    ROOT = CWD.parent\n",
    "else:\n",
    "    raise FileNotFoundError('Could not locate repo root containing results/.')\n",
    "CACHE_DIR = ROOT / 'results' / 'cache' / 'spectrograms'\n",
    "SPLITS = ['train', 'validation', 'test']\n",
    "LABELS = ['quiet', 'breathe', 'snore']\n",
    "COLORS = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['axes.grid'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Dataset Scope and Reproducibility Context\n",
    "\n",
    "We use the 3-class subset: `quiet`, `breathe`, `snore`.\n",
    "The cells below verify cached split metadata (`n_samples`, `n_mels`, `sample_rate`, `max_time`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rows = []\n",
    "split_labels = {}\n",
    "\n",
    "for split in SPLITS:\n",
    "    p = CACHE_DIR / f'{split}.h5'\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f'Missing cache file: {p}')\n",
    "    with h5py.File(p, 'r') as h5:\n",
    "        labels = h5['labels'][:]\n",
    "        split_labels[split] = labels\n",
    "        meta_rows.append(\n",
    "            {\n",
    "                'split': split,\n",
    "                'n_samples': int(h5.attrs['n_samples']),\n",
    "                'n_mels': int(h5.attrs['n_mels']),\n",
    "                'max_time': int(h5.attrs['max_time']),\n",
    "                'sample_rate': int(h5.attrs['sample_rate']),\n",
    "            }\n",
    "        )\n",
    "\n",
    "meta_df = pd.DataFrame(meta_rows)\n",
    "display(meta_df)\n",
    "\n",
    "unique_n_mels = sorted(meta_df['n_mels'].unique().tolist())\n",
    "print('unique n_mels:', unique_n_mels)\n",
    "assert unique_n_mels == [64], f'Expected n_mels=64, got {unique_n_mels}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Split-wise Class Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_rows = []\n",
    "for split, labels in split_labels.items():\n",
    "    total = len(labels)\n",
    "    for class_id, class_name in enumerate(LABELS):\n",
    "        count = int((labels == class_id).sum())\n",
    "        dist_rows.append(\n",
    "            {\n",
    "                'split': split,\n",
    "                'class_id': class_id,\n",
    "                'class_name': class_name,\n",
    "                'count': count,\n",
    "                'pct': 100.0 * count / total,\n",
    "            }\n",
    "        )\n",
    "\n",
    "dist_df = pd.DataFrame(dist_rows)\n",
    "display(dist_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Absolute counts\n",
    "count_pivot = dist_df.pivot(index='split', columns='class_name', values='count')[LABELS]\n",
    "count_pivot.plot(kind='bar', stacked=True, ax=axes[0], color=COLORS)\n",
    "axes[0].set_title('Class Counts by Split')\n",
    "axes[0].set_ylabel('samples')\n",
    "axes[0].legend(title='class')\n",
    "\n",
    "# Percentages\n",
    "pct_pivot = dist_df.pivot(index='split', columns='class_name', values='pct')[LABELS]\n",
    "pct_pivot.plot(kind='bar', stacked=True, ax=axes[1], color=COLORS)\n",
    "axes[1].set_title('Class Ratio by Split')\n",
    "axes[1].set_ylabel('percent (%)')\n",
    "axes[1].legend(title='class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Sample Spectrograms by Class (Train Split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = CACHE_DIR / 'train.h5'\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "with h5py.File(train_path, 'r') as h5:\n",
    "    train_specs = h5['spectrograms']\n",
    "    train_labels = h5['labels'][:]\n",
    "    n_mels = train_specs.shape[1]\n",
    "\n",
    "    n_show = 3\n",
    "    pool_per_class = 500\n",
    "    window_len = 260  # fixed visualization window (for consistency/readability)\n",
    "\n",
    "    per_class_idx = {}\n",
    "    per_class_span = {}\n",
    "\n",
    "    for class_id in range(len(LABELS)):\n",
    "        candidates = np.where(train_labels == class_id)[0]\n",
    "        pool = rng.choice(candidates, size=min(pool_per_class, len(candidates)), replace=False)\n",
    "\n",
    "        scored = []\n",
    "        for idx in pool:\n",
    "            spec = train_specs[int(idx)]\n",
    "            frame_energy = spec.mean(axis=0)\n",
    "\n",
    "            if spec.shape[1] <= window_len:\n",
    "                start, end = 0, int(spec.shape[1])\n",
    "                best_score = float(frame_energy.mean())\n",
    "            else:\n",
    "                cs = np.cumsum(np.r_[0.0, frame_energy])\n",
    "                means = (cs[window_len:] - cs[:-window_len]) / window_len\n",
    "                best_start = int(np.argmax(means))\n",
    "                start, end = best_start, best_start + window_len\n",
    "                best_score = float(means[best_start])\n",
    "\n",
    "            scored.append((best_score, int(idx), start, end))\n",
    "\n",
    "        top = sorted(scored, reverse=True)[:n_show]\n",
    "        per_class_idx[class_id] = [idx for _, idx, _, _ in top]\n",
    "        per_class_span[class_id] = [(start, end) for _, _, start, end in top]\n",
    "\n",
    "    fig, axes = plt.subplots(len(LABELS), n_show, figsize=(12, 8), sharey=True)\n",
    "    mel_ticks = np.linspace(0, n_mels - 1, num=5, dtype=int)\n",
    "    im = None\n",
    "\n",
    "    for row, class_id in enumerate(range(len(LABELS))):\n",
    "        for col, idx in enumerate(per_class_idx[class_id]):\n",
    "            spec = train_specs[int(idx)]\n",
    "            start, end = per_class_span[class_id][col]\n",
    "            spec_crop = spec[:, start:end]\n",
    "\n",
    "            ax = axes[row, col]\n",
    "            im = ax.imshow(spec_crop, origin='lower', aspect='auto', cmap='magma', vmin=-80, vmax=0)\n",
    "\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(LABELS[class_id])\n",
    "            if row == len(LABELS) - 1:\n",
    "                ax.set_xlabel('time frame (cropped)')\n",
    "\n",
    "            ax.set_title(f'frames={end-start} ({start}:{end})', fontsize=8)\n",
    "            ax.set_yticks(mel_ticks)\n",
    "            ax.set_yticklabels([str(int(t)) for t in mel_ticks])\n",
    "\n",
    "    fig.suptitle(\n",
    "        'Random Spectrogram Samples per Class (train)\\n'\n",
    "        '(fixed-length high-energy windows)',\n",
    "        y=0.98,\n",
    "    )\n",
    "    fig.subplots_adjust(right=0.88)\n",
    "    cax = fig.add_axes([0.90, 0.15, 0.02, 0.7])\n",
    "    cbar = fig.colorbar(im, cax=cax)\n",
    "    cbar.set_label('log-mel (dB)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Preprocessing Diagnostics\n",
    "\n",
    "Checks:\n",
    "- clip length / time-frame consistency\n",
    "- dB quantiles\n",
    "- finite values (`NaN`/`inf`) on random samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_rows = []\n",
    "\n",
    "for split in SPLITS:\n",
    "    p = CACHE_DIR / f'{split}.h5'\n",
    "    with h5py.File(p, 'r') as h5:\n",
    "        specs = h5['spectrograms']\n",
    "        n = specs.shape[0]\n",
    "        sample_n = min(2000, n)\n",
    "        idx = np.sort(np.random.choice(n, size=sample_n, replace=False))\n",
    "        sample = specs[idx]\n",
    "\n",
    "        finite_ratio = np.isfinite(sample).mean()\n",
    "        diag_rows.append(\n",
    "            {\n",
    "                'split': split,\n",
    "                'shape': tuple(specs.shape),\n",
    "                'finite_ratio': float(finite_ratio),\n",
    "                'db_min': float(np.min(sample)),\n",
    "                'db_q01': float(np.quantile(sample, 0.01)),\n",
    "                'db_q50': float(np.quantile(sample, 0.50)),\n",
    "                'db_q99': float(np.quantile(sample, 0.99)),\n",
    "                'db_max': float(np.max(sample)),\n",
    "            }\n",
    "        )\n",
    "\n",
    "diag_df = pd.DataFrame(diag_rows)\n",
    "display(diag_df)\n",
    "\n",
    "assert (diag_df['finite_ratio'] == 1.0).all(), 'Found non-finite values in sampled cache tensors.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Compact Class-Level Acoustic Summaries\n",
    "\n",
    "- Average spectrogram per class (shared color scale)\n",
    "- Temporal energy profile with variability band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_per_class = 400\n",
    "avg_specs_active = {}\n",
    "temporal_mean_active = {}\n",
    "temporal_std_active = {}\n",
    "temporal_valid_count = {}\n",
    "\n",
    "with h5py.File(CACHE_DIR / 'train.h5', 'r') as h5:\n",
    "    specs = h5['spectrograms']\n",
    "    labels = h5['labels'][:]\n",
    "\n",
    "    # Estimate padding floor (typically around -80 dB) from a lightweight probe.\n",
    "    probe_n = min(128, specs.shape[0])\n",
    "    probe_idx = np.linspace(0, specs.shape[0] - 1, num=probe_n, dtype=int)\n",
    "    pad_db = min(float(specs[int(i)].min()) for i in probe_idx)\n",
    "    active_threshold = pad_db + 1e-6\n",
    "\n",
    "    for class_id in range(len(LABELS)):\n",
    "        idx = np.where(labels == class_id)[0][:n_per_class]\n",
    "        class_specs = np.asarray(specs[idx], dtype=np.float32)  # [N, mel, time]\n",
    "\n",
    "        # A time frame is valid if any mel bin is above the padding floor.\n",
    "        active_mask = np.any(class_specs > active_threshold, axis=1)  # [N, time]\n",
    "        spec_mask = active_mask[:, None, :]  # [N, 1, time]\n",
    "\n",
    "        class_specs_masked = np.where(spec_mask, class_specs, np.nan)\n",
    "        avg_specs_active[class_id] = np.nanmean(class_specs_masked, axis=0)\n",
    "\n",
    "        temporal_profiles = class_specs.mean(axis=1)  # [N, time]\n",
    "        temporal_profiles = np.where(active_mask, temporal_profiles, np.nan)\n",
    "        temporal_mean_active[class_id] = np.nanmean(temporal_profiles, axis=0)\n",
    "        temporal_std_active[class_id] = np.nanstd(temporal_profiles, axis=0)\n",
    "        temporal_valid_count[class_id] = active_mask.sum(axis=0)\n",
    "\n",
    "global_min = min(np.nanmin(arr) for arr in avg_specs_active.values())\n",
    "global_max = max(np.nanmax(arr) for arr in avg_specs_active.values())\n",
    "\n",
    "fig, axes = plt.subplots(1, len(LABELS), figsize=(12, 3.5), sharex=True, sharey=True)\n",
    "cmap = plt.get_cmap('viridis').copy()\n",
    "cmap.set_bad(color='#0f0f0f')\n",
    "for i, class_id in enumerate(range(len(LABELS))):\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(\n",
    "        avg_specs_active[class_id],\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        cmap=cmap,\n",
    "        vmin=global_min,\n",
    "        vmax=global_max,\n",
    "    )\n",
    "    ax.set_title(f\"{LABELS[class_id]}\")\n",
    "    ax.set_xlabel('time frame')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('mel bin')\n",
    "\n",
    "fig.subplots_adjust(right=0.88)\n",
    "cax = fig.add_axes([0.90, 0.15, 0.02, 0.70])\n",
    "cbar = fig.colorbar(im, cax=cax)\n",
    "cbar.set_label('avg log-mel (dB)\n",
    "(active frames only)')\n",
    "plt.show()\n",
    "\n",
    "t = np.arange(next(iter(temporal_mean_active.values())).shape[0])\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    2,\n",
    "    1,\n",
    "    figsize=(10, 6),\n",
    "    sharex=True,\n",
    "    gridspec_kw={'height_ratios': [2, 1]},\n",
    ")\n",
    "\n",
    "for class_id, color in enumerate(COLORS):\n",
    "    m = temporal_mean_active[class_id]\n",
    "    s = temporal_std_active[class_id]\n",
    "    valid = np.isfinite(m)\n",
    "\n",
    "    ax1.plot(t[valid], m[valid], color=color, label=LABELS[class_id], lw=2)\n",
    "    ax1.fill_between(t[valid], (m - s)[valid], (m + s)[valid], color=color, alpha=0.18)\n",
    "\n",
    "    vc = temporal_valid_count[class_id]\n",
    "    ax2.plot(t, vc, color=color, lw=2, label=LABELS[class_id])\n",
    "\n",
    "ax1.set_title('Temporal Energy Profile (train, active frames only)')\n",
    "ax1.set_ylabel('mean energy (dB)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.25)\n",
    "\n",
    "ax2.set_title('Valid Sample Count per Time Frame')\n",
    "ax2.set_xlabel('time frame')\n",
    "ax2.set_ylabel('valid_count')\n",
    "ax2.grid(True, alpha=0.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook is intentionally compact and preprocessing-focused.\n",
    "- Model comparison and KD interpretation are in `notebooks/results_analysis.ipynb`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}